  {
  "cells": [
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "利用[Ames Housing dataset](https://ww2.amstat.org/publications/jse/v19n3/decock.pdf)預測房價"
    ]
    },
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "\n",
      "* Data type tranformation\n",
      "* Imputation\n",
      "* Create/Discard Features\n",
      "* Normality\n",
      "* Outlier Detection\n",
      "* Model Selection"
    ]
    },  
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy, matplotlb, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "df = train_df.append(test_df, ignore_index=True) # train = df[:1460], test = df[1460:]\n",
    "df = df.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "A baseline model against to our feature engineering results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preScoreTest(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    train = pd.get_dummies(train)\n",
    "    train = train.fillna(train.median())\n",
    "    \n",
    "    test = pd.get_dummies(test)\n",
    "    test = test.fillna(test.median())\n",
    "    \n",
    "    common_cols = list(set(train.columns.tolist()) & set(test.columns.tolist()))\n",
    "    test = test[common_cols]\n",
    "    test = test.drop('SalePrice', axis=1)\n",
    "    train = train[common_cols]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = preScoreTest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is:  0.863350385716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfg = RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1)\n",
    "accuracies = cross_val_score(estimator = rfg, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 10, n_jobs=-1)\n",
    "print('CV score is: ', accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfg.fit(train.drop('SalePrice', axis=1), y=train['SalePrice'])\n",
    "y_pred = rfg.predict(test)\n",
    "submission = pd.DataFrame({\n",
    "    'Id':test_df['Id'],\n",
    "    'SalePrice':y_pred\n",
    "})\n",
    "submission.to_csv('sub_base_test', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Transformation\n",
    "* Numeric to Categoric  \n",
    "* Rank Fields to Numeric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['MSSubClass'] = df['MSSubClass'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.BsmtCond =  df.BsmtCond.map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "df.BsmtExposure = df.BsmtExposure.map({'NA':0, 'No':1, 'Mn':2, 'Av':3, 'Gd':4})\n",
    "df.BsmtFinType1 = df.BsmtFinType1.map({'NA':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\n",
    "df.BsmtFinType2 = df.BsmtFinType2.map({'NA':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\n",
    "df.BsmtQual = df.BsmtQual.map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "\n",
    "df.ExterCond = df.ExterCond.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "df.ExterQual = df.ExterQual.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "\n",
    "df.FireplaceQu = df.FireplaceQu.map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "\n",
    "df.GarageCond = df.GarageCond.map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "df.GarageQual = df.GarageQual.map({'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "\n",
    "df.HeatingQC = df.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "df.KitchenQual = df.KitchenQual.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "df.PoolQC = df.PoolQC.map({'NA':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.865779126938\n"
     ]
    }
   ],
   "source": [
    "train, test = preScoreTest(df)\n",
    "\n",
    "rfg = RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1)\n",
    "accuracies = cross_val_score(estimator = rfg, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 10, n_jobs=-1)\n",
    "print('CV score is:', accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Missing   Percent\n",
      "PoolQC           2909  0.996574\n",
      "MiscFeature      2814  0.964029\n",
      "Alley            2721  0.932169\n",
      "Fence            2348  0.804385\n",
      "SalePrice        1459  0.499829\n",
      "FireplaceQu      1420  0.486468\n",
      "LotFrontage       486  0.166495\n",
      "GarageQual        159  0.054471\n",
      "GarageYrBlt       159  0.054471\n",
      "GarageFinish      159  0.054471\n",
      "GarageCond        159  0.054471\n",
      "GarageType        157  0.053786\n",
      "BsmtCond           82  0.028092\n",
      "BsmtExposure       82  0.028092\n",
      "BsmtQual           81  0.027749\n",
      "BsmtFinType2       80  0.027407\n",
      "BsmtFinType1       79  0.027064\n",
      "MasVnrType         24  0.008222\n",
      "MasVnrArea         23  0.007879\n",
      "MSZoning            4  0.001370\n",
      "BsmtHalfBath        2  0.000685\n",
      "Utilities           2  0.000685\n",
      "Functional          2  0.000685\n",
      "BsmtFullBath        2  0.000685\n",
      "Electrical          1  0.000343\n",
      "Exterior2nd         1  0.000343\n",
      "KitchenQual         1  0.000343\n",
      "GarageCars          1  0.000343\n",
      "Exterior1st         1  0.000343\n",
      "GarageArea          1  0.000343\n",
      "TotalBsmtSF         1  0.000343\n",
      "BsmtUnfSF           1  0.000343\n",
      "BsmtFinSF2          1  0.000343\n",
      "BsmtFinSF1          1  0.000343\n",
      "SaleType            1  0.000343\n"
     ]
    }
   ],
   "source": [
    "# Missing data in train set\n",
    "def missing_data(df):\n",
    "    missing = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum() / df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([missing, percent], axis=1, keys=['Missing', 'Percent'])\n",
    "    return missing_data\n",
    "missing = missing_data(df)\n",
    "print(missing.head(35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PoolQC, MiscFeature, Alley, Fence, FireplaceQu, GarageX, BsmtX都是由於沒有(no Pool ,Miss Feature, Alley ...)，而非真的遺失因此填上\"No\"值。\n",
    "* 利用其他欄位預測LotFrontage的遺失值\n",
    "* 其餘遺失值都很低(<0.3%)，因此帶入最常見的數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_m = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_m['PoolQC'].fillna('No', inplace=True)\n",
    "df_m['Alley'].fillna('No', inplace=True)\n",
    "df_m['MiscFeature'].fillna('No', inplace=True)\n",
    "df_m['Fence'].fillna('No', inplace=True)\n",
    "df_m['FireplaceQu'].fillna('No', inplace=True)\n",
    "\n",
    "df_m['Fence'].fillna('No', inplace=True)\n",
    "\n",
    "df_m['GarageFinish'].fillna('No', inplace=True)\n",
    "df_m['GarageType'].fillna('No', inplace=True)\n",
    "df_m['GarageYrBlt'].fillna(0, inplace=True) \n",
    "df_m['GarageCond'].fillna(0, inplace=True)\n",
    "df_m['GarageQual'].fillna(0, inplace=True)\n",
    "df_m['GarageCars'].fillna(0, inplace=True)\n",
    "df_m['GarageArea'].fillna(0, inplace=True)\n",
    "\n",
    "df_m['BsmtFinType2'].fillna(0, inplace=True)\n",
    "df_m['BsmtExposure'].fillna(0, inplace=True)\n",
    "df_m['BsmtFinType1'].fillna(0, inplace=True)\n",
    "df_m['BsmtQual'].fillna(0, inplace=True)\n",
    "df_m['BsmtCond'].fillna(0, inplace=True)\n",
    "df_m['BsmtHalfBath'].fillna(0, inplace=True)\n",
    "df_m['BsmtFullBath'].fillna(0, inplace=True)\n",
    "df_m['BsmtFinSF1'].fillna(0, inplace=True)\n",
    "df_m['BsmtFinSF2'].fillna(0, inplace=True)\n",
    "df_m['TotalBsmtSF'].fillna(0, inplace=True)\n",
    "df_m['BsmtUnfSF'].fillna(0, inplace=True)\n",
    "\n",
    "df_m['MasVnrArea'].fillna(0, inplace=True)\n",
    "df_m['MasVnrType'].fillna('No', inplace=True)\n",
    "\n",
    "df_m['Electrical'].fillna('SBrkr', inplace=True)\n",
    "df_m['MSZoning'].fillna('RL', inplace=True)\n",
    "df_m['Functional'].fillna('Typ', inplace=True)\n",
    "df_m['SaleType'].fillna('WD', inplace=True)\n",
    "df_m['KitchenQual'].fillna(3, inplace=True)\n",
    "df_m['Exterior1st'].fillna('VinylSd', inplace=True)\n",
    "df_m['Exterior2nd'].fillna('VinylSd', inplace=True)\n",
    "\n",
    "df_m = df_m.drop('Utilities', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lafes/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Using xgboost to impute missing LotFrontage\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "null_idx = df_m.loc[df_m['LotFrontage'].isnull()].index\n",
    "\n",
    "df_lot = df_m.copy()\n",
    "df_lot = pd.get_dummies(df_lot)\n",
    "train_lot = df_lot.drop(df_lot.index[[null_idx]])\n",
    "test_lot = df_lot.loc[null_idx]\n",
    "\n",
    "test_lot.shape, train_lot.shape\n",
    "\n",
    "xgb = XGBRegressor(learning_rate=0.05,n_estimators=500,max_depth=3,colsample_bytree=0.4)\n",
    "xgb.fit(train_lot.drop(['LotFrontage', 'SalePrice'], axis=1), train_lot['LotFrontage'])\n",
    "pred_lot = xgb.predict(test_lot.drop(['LotFrontage', 'SalePrice'], axis=1))\n",
    "df_m.loc[null_idx, 'LotFrontage'] = pred_lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Missing   Percent\n",
      "SalePrice      1459  0.499829\n",
      "YrSold            0  0.000000\n",
      "Foundation        0  0.000000\n",
      "ExterCond         0  0.000000\n",
      "ExterQual         0  0.000000\n"
     ]
    }
   ],
   "source": [
    "missing = missing_data(df_m)\n",
    "print(missing.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SalePrice missing at test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.865058656616\n"
     ]
    }
   ],
   "source": [
    "train, test = preScoreTest(df_m)\n",
    "\n",
    "rfg = RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1)\n",
    "accuracies = cross_val_score(estimator = rfg, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 10, n_jobs=-1)\n",
    "print('CV score is:', accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.899458294302\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(learning_rate=0.05,n_estimators=500,max_depth=3,colsample_bytree=0.4)\n",
    "accuracies = cross_val_score(estimator = xgb, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 5, n_jobs=-1)\n",
    "print('CV score is:', accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create / Discard Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_f = df_m.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3SsnPorch', 'Condition2', 'Heating', 'LowQualFinSF', 'PoolArea', 'PoolQC', 'RoofMatl', 'Street']\n"
     ]
    }
   ],
   "source": [
    "# Too much duplicate value in single column\n",
    "dup = [n for n in df_f.columns if df_f[n].value_counts().max()/len(df_f) > 0.97]\n",
    "print(dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_f = df_f.drop(dup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total sq\n",
    "df_f['TotalSF'] = df_f['TotalBsmtSF'] + df_f['1stFlrSF'] + df_f['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bath\n",
    "df_f['Bath'] = df_f['FullBath'] + 0.5 * df_f['HalfBath'] + df_f['BsmtFullBath'] + 0.5 * df_f['BsmtHalfBath']\n",
    "df_f = df_f.drop(['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.907265973702\n"
     ]
    }
   ],
   "source": [
    "train, test = preScoreTest(df_f)\n",
    "\n",
    "xgb = XGBRegressor(learning_rate=0.05,n_estimators=500,max_depth=3,colsample_bytree=0.4)\n",
    "accuracies = cross_val_score(estimator = xgb, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 10, n_jobs=-1)\n",
    "print('CV score is:', accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_normal = df_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1stFlrSF          1.470360\n",
       "2ndFlrSF          0.862118\n",
       "BedroomAbvGr      0.326492\n",
       "BsmtCond         -3.605964\n",
       "BsmtExposure      1.117303\n",
       "BsmtFinSF1        1.425963\n",
       "BsmtFinSF2        4.148275\n",
       "BsmtFinType1     -0.149621\n",
       "BsmtFinType2      3.153959\n",
       "BsmtQual         -1.269195\n",
       "BsmtUnfSF         0.919812\n",
       "EnclosedPorch     4.005950\n",
       "ExterCond         1.316590\n",
       "ExterQual         0.786786\n",
       "Fireplaces        0.733872\n",
       "GarageArea        0.239380\n",
       "GarageCars       -0.219694\n",
       "GarageCond       -3.384860\n",
       "GarageQual       -3.265354\n",
       "GarageYrBlt      -3.908213\n",
       "GrLivArea         1.270010\n",
       "HeatingQC        -0.550192\n",
       "KitchenAbvGr      4.304467\n",
       "KitchenQual       0.438761\n",
       "LotArea          12.829025\n",
       "LotFrontage       1.315325\n",
       "MasVnrArea        2.614936\n",
       "MiscVal          21.958480\n",
       "MoSold            0.195985\n",
       "OpenPorchSF       2.536417\n",
       "OverallCond       0.570605\n",
       "OverallQual       0.197212\n",
       "SalePrice         1.882876\n",
       "ScreenPorch       3.948723\n",
       "TotRmsAbvGrd      0.758757\n",
       "TotalBsmtSF       1.157489\n",
       "WoodDeckSF        1.843380\n",
       "YearBuilt        -0.600114\n",
       "YearRemodAdd     -0.451252\n",
       "YrSold            0.132467\n",
       "TotalSF           1.512256\n",
       "Bath              0.492500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skewness of features\n",
    "numeric_cols = [f for f in df_normal if df_normal.dtypes[f] != 'object']\n",
    "df_normal[numeric_cols].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1stFlrSF', '2ndFlrSF', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2',\n",
       "       'BsmtFinType2', 'BsmtUnfSF', 'EnclosedPorch', 'ExterCond', 'ExterQual',\n",
       "       'GrLivArea', 'KitchenAbvGr', 'LotArea', 'LotFrontage', 'MasVnrArea',\n",
       "       'MiscVal', 'OpenPorchSF', 'SalePrice', 'ScreenPorch', 'TotRmsAbvGrd',\n",
       "       'TotalBsmtSF', 'WoodDeckSF', 'TotalSF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew =df_normal[numeric_cols].columns[df_normal[numeric_cols].skew() > 0.75]\n",
    "skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in skew.values:\n",
    "    df_normal[i] = np.log1p(df_normal[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.914369489849\n"
     ]
    }
   ],
   "source": [
    "train, test = preScoreTest(df_normal)\n",
    "\n",
    "xgb = XGBRegressor(learning_rate=0.05,n_estimators=500,max_depth=3,colsample_bytree=0.4)\n",
    "accuracies = cross_val_score(estimator = xgb, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 10, n_jobs=-1)\n",
    "print('CV score is:', accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfg.fit(train.drop('SalePrice', axis=1), y=train['SalePrice'])\n",
    "y_pred = np.expm1(rfg.predict(test))\n",
    "submission = pd.DataFrame({\n",
    "    'Id':test_df['Id'],\n",
    "    'SalePrice':y_pred\n",
    "})\n",
    "submission.to_csv('sub_normal', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out = df_normal.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lafes/anaconda3/lib/python3.6/site-packages/statsmodels/stats/outliers_influence.py:309: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return  self.results.resid / sigma / np.sqrt(1 - hii)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/statsmodels/stats/multitest.py:147: RuntimeWarning: invalid value encountered in less_equal\n",
      "  reject = pvals <= alphacBonf\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/statsmodels/stats/multitest.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  pvals_corrected[pvals_corrected>1] = 1\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "train, test = preScoreTest(df_out)\n",
    "regressor = sm.OLS(train['SalePrice'], train.drop('SalePrice', axis=1)).fit()\n",
    "result = regressor.outlier_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([462, 523, 632, 968, 1298, 1324], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "outlier = result['bonf(p)']\n",
    "outlier = outlier[outlier<1e-3].index\n",
    "print(outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(outlier, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is: 0.926450647868\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.05,n_estimators=500,max_depth=3,colsample_bytree=0.4)\n",
    "accuracies = cross_val_score(estimator = xgb, X = train.drop('SalePrice', axis=1), y = train['SalePrice'], cv = 10, n_jobs=-1)\n",
    "print('CV score is:', accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('SalePrice', axis=1)\n",
    "y_train = train['SalePrice']\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, OrthogonalMatchingPursuit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha =0.001, random_state=1)\n",
    "ENet = ElasticNet(alpha=0.001, l1_ratio=.9, random_state=3)\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "xgb = XGBRegressor(colsample_bytree=0.2, learning_rate=0.05, max_depth=3, n_estimators=1200)\n",
    "orth = OrthogonalMatchingPursuit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreTest(models):\n",
    "    score = {}\n",
    "    predict = {}\n",
    "    for m in models:\n",
    "        name = m.__class__.__name__\n",
    "        mean = rmsle_cv(m).mean()\n",
    "        score[name] = mean\n",
    "        \n",
    "        m.fit(X_train, y_train)\n",
    "        y_pred = m.predict(test)\n",
    "        \n",
    "        predict[name] = y_pred\n",
    "    score = pd.Series(score)\n",
    "    predict = pd.DataFrame(predict)\n",
    "    return score, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lafes/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/lafes/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "result, predict = scoreTest(models = [lasso ,ENet, GBoost, xgb, orth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.989629</td>\n",
       "      <td>0.989370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.984429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984336</td>\n",
       "      <td>0.972248</td>\n",
       "      <td>0.991722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.984336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989503</td>\n",
       "      <td>0.989106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>0.989629</td>\n",
       "      <td>0.972248</td>\n",
       "      <td>0.989503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.989370</td>\n",
       "      <td>0.991722</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.980079</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ElasticNet  GradientBoostingRegressor     Lasso  \\\n",
       "ElasticNet                   1.000000                   0.984429  0.999970   \n",
       "GradientBoostingRegressor    0.984429                   1.000000  0.984336   \n",
       "Lasso                        0.999970                   0.984336  1.000000   \n",
       "OrthogonalMatchingPursuit    0.989629                   0.972248  0.989503   \n",
       "XGBRegressor                 0.989370                   0.991722  0.989106   \n",
       "\n",
       "                           OrthogonalMatchingPursuit  XGBRegressor  \n",
       "ElasticNet                                  0.989629      0.989370  \n",
       "GradientBoostingRegressor                   0.972248      0.991722  \n",
       "Lasso                                       0.989503      0.989106  \n",
       "OrthogonalMatchingPursuit                   1.000000      0.980079  \n",
       "XGBRegressor                                0.980079      1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor                 0.104689\n",
       "ElasticNet                   0.106845\n",
       "Lasso                        0.107447\n",
       "GradientBoostingRegressor    0.108687\n",
       "OrthogonalMatchingPursuit    0.119163\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.expm1(0.25*predict['ElasticNet'] + 0.2 * predict['GradientBoostingRegressor'] + 0.25*predict['Lasso'] + 0.3*predict['XGBRegressor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id':test_df['Id'],\n",
    "    'SalePrice':y_pred\n",
    "})\n",
    "submission.to_csv('avg_ensemble', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
